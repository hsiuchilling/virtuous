---
title: "dsShenanigans1"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, fig.align = 'center')
library(broom)
library(dplyr)
library(ggplot2)
library(knitr)
library(magrittr)
library(purrr)
library(scales)
library(SurvRegCensCov)
library(survival)
library(tibble)
library(tidyr)
data(lung)
lung %<>%
  mutate(status = ifelse(status == 2, 1, 0), 
         sex = ifelse(sex == 1, "Male", "Female"))

m <- survfit(Surv(time, status)~sex, data = lung)
survData <- data.frame(day = m$time,
                       sex = rep(names(m$strata), times = m$strata),
                       surv = m$surv,
                       upper = m$upper, 
                       lower = m$lower) %>%
  mutate(Sex = ifelse(sex == "sex=Male", "Male", "Female"))
```

## Data Science and Baby Food

I am increasingly convinced that there are strong parallels between data science and the baby food manufacture industry. Both are tasked with processing raw material into palatable and easy-to-digest portions. Further, the product need not only be consumable, but also safe; it should be hard to hurt people and babies with baby food, and data analyses should likewise be constructed and tested such that it is difficult to misinterpret and unlikely to cause harm. We are people in the business of trust, certifying broader statements that are conducive to making business decisions while backing recommendations behind the scenes with thorough diagnostics and solid statistical foundations. We gain trust in the instances where we are right (cue the bitter ironic laughter) and I would venture that we also gain credibility when we give prudent forewarning where it is due.

## Survival

### Assumptions and additives

Recently, we were interested in how susceptible different demographics in our client base are to churn and how long we may expect a client to retain us for our services. For privacy reasons, we're going to substitute the client data with the lung data set from the survival package and entertain the question of whether gender plays a role in survivorship of advanced lung cancer. We can take the data and plot the survivorship curves for males and females:

```{r}
survData %>%
  ggplot() +
  geom_line(aes(x = day, y = surv, color = Sex, group = Sex)) +
  geom_ribbon(aes(x = day, ymax = upper, 
                  ymin = lower, fill = Sex, group = Sex),
              alpha = .2) +
  scale_y_continuous(name = "Survival", label = percent) +
  scale_x_continuous(name = "Day", label = comma) + 
  theme_bw()
```

Already though, we can ask if we've done a good job in even just displaying a plot. Will our audience understand the graphic, and do we even understand it? Maybe it's reasonable to assume that survival curves are intuitive; at the beginning 100% of all participants are alive and the curves decline over time when people pass on. But where did the intervals come from? Did we assume some distribution? Did we replicate the experiment enough such that we have empirical quantiles for each point in time?

Do we know what we're presenting?

The answer is that the intervals are computed using an approximation called Greenwood's formula which obtains the estimates by leveraging a few assumptions about the data (e.g. assuming deaths in small time segments are Binomial). However, the moment we put up this plot, we've subscribed to those assumptions and it's problematic if we aren't aware of them or if we haven't thought about how suitable they are to our use case. If the assumptions are poor, then we've put some unknown additives in our baby food and we've poisoned people. Knowing Greenwood's formula off the top of our heads isn't very important, but understanding when it could be terribly wrong and broadcasting our concerns is central to the data science job description. In this case, the approximation may have been bad if nurses record time of death in batches or if even small time differences lead to substantial changes in probability of death. These intervals were automatically generated by a package, but presenting these curves comes with a promise that we have thoroughly thought about the legitimacy of all components of the chart.

### Regression and packaging

Now suppose we need to more concretely quantify the effect of gender on survivorship. To do this, we can assume that our data follows some distribution with some parameters $\theta_i$:

$$
Y_i \sim f_{\theta_i}(y).
$$

We now have to find a way to relate the above to the information we have about observation i or else we haven't made good use of our data. A good candidate to relate our covariates to the distribution f might be the parameter $\theta_i$, because $\theta_i$ determines the shape of our distribution. For example, a common distribution used in survival modeling is the Weibull distribution which has two parameters, shape and scale. Here we can see how different values of the parameters might change how the distribution appears:

```{r}
shape <- c(1, 5, 10)
scale = c(100, 200, 500)
weibullDist <- function(shape, scale) {
  res <- data.frame(x = seq(0, 1000, 1)) %>%
    mutate(ps = dweibull(x, shape, scale))
  return(res)
}
expand.grid(shape = shape, scale = scale) %>%
  mutate(data = map2(shape, scale, weibullDist)) %>%
  unnest() %>%
  mutate(shape = factor(paste("Shape =", shape),
                        levels = c("Shape = 1", "Shape = 5",
                                   "Shape = 10")),
         scale = paste("Scale =", scale)) %>%
  ggplot(aes(x = x, y = ps)) +
  geom_line() +
  facet_grid(shape~scale, scales = "free") +
  scale_x_continuous(name = "Days Survived", labels = comma) + 
  ylab("Weibull Density") +
  theme_bw()
```

Then it may be a good idea to find estimates of $\theta_i$ such that the distribution best fits our data. A common approach is to say that some link function g of $\theta_i$ is linearly related to our covariates. This incorporates our data set in our analysis by establishing the relationship

$$
g(\theta_i) = \beta_0 + \sum_{i = 1}^k X_{ik}\beta_k
$$
where $X_{ik}$ is the kth covariate of the ith observation, $\beta_0$ is an intercept term, and $\beta_1, ..., \beta_k$ are the coefficients. Our job is to find estimates of the coefficients because they explain how our data relates to $\theta_i$ which in turn determines the shape of the distribution. This approach is called a generalized linear model. In our case, we have exactly one covariate, gender, and by assuming a log link function for the shape parameter, $s_i$, we can write

$$
\log(s_i) = \beta_0 + \mathbb{I}_{i, \text{male}}\beta_1
$$
where $\mathbb{I}_{i, male}$ is our data and is an indicator that takes the value 1 when person i is male and is 0 otherwise. Taking all of this we can use R to find the estimates for $\beta_0$ and $\beta_1$:

```{r}
m <- survreg(Surv(time,status)~sex, data = lung)
m %>%
  summary %>%
  coef %>%
  as.data.frame %>%
  rownames_to_column %>%
  setNames(c("Covariate", "Value")) %>%
  mutate(Value = round(Value, 2)) %>%
  kable
```

We have our estimates but what do they mean? If I reported that being male on average is associated with a 0.4 decrease of the shape parameter on the log scale, then I'd be right but I'd probably also have to update my LinkedIn profile in the near future. We are responsible not only for finding estimates of the coefficients but also for providing ways of interpreting our results intuitively. Baby food should be easily digestible, but getting to that stage requires work. Instead of reporting the coefficients outright, we can process our results with a bit of math. It turns out that the hazard function of the Weibull distribution can be written as

$$
h(y) = ay^{b-1}\exp(\log(s))= a y^{b - 1}\exp\left(\beta_0 + \mathbb{I}_{\text{male}}\beta_1\right)
$$
where $a$ and $b$ are constants not involving the time of death $y$ or the shape parameter. Then if we divide the hazard of a male by the hazard of a female we get the hazard ratio (HR) of gender:

$$
HR(\beta_1) = \frac{ay^{b-1}\exp(\beta_0 + \beta_1)}{ay^{b-1}\exp(\beta_0)} = \exp(\beta_1).
$$

This equation shows that if we exponentiate $\beta_1$ then we have an interpretable result; namely, how many times more hazard is associated with being male in comparison to being female.
Another quantity related to the Weibull distribution is the amount of time it takes until only proportion $p$ of the patients remain. We'll call this $Q_p$ and it can be written as

$$
Q_p = \left(\frac{- \log p}{c \exp(\beta_0 + \mathbb{I}_{\text{male}}\beta_1)}\right)^{1/ b}
$$

where $c$ is another constant. Taking a similar approach as with the hazard ratio, we can compute the ratio of the respective $Q_p$'s for males and females

$$
\frac{Q_{p, \text{male}}}{Q_{p, \text{female}}} = \exp\left(\frac{\beta_1}{b}\right).
$$

Then we can interpret this quantity as how many times longer it takes for a proportion of males to pass on as it takes for the same proportion of females to also pass on. The first ratio gives a sense of how much more mortality males are exposed to than females and the second ratio gives a sense of the time discrepancy between the two genders; both are more interpretable than the coefficient alone. Taking these findings we can compute the ratios here:

```{r}
output <- ConvertWeibull(m)
rbind(output$HR, output$ETR) %>%
  as.data.frame() %>%
  rename(value = HR) %>%
  mutate(value = round(value, 2),
         LB = round(LB, 2),
         UB = round(UB, 2)) %>%
  mutate(Statistic = c("Hazard Ratio", "Event Time Ratio")) %>%
  select(Statistic, Value = value, LB, UB) %>%
  kable
```

At the end of the day, these derivations were done previously by somebody who was an expert in survival modeling. Being able to independently understand existing methods and to present interpretable and actionable results are my contributions to the team. We process data into a form that is more widely consumable and accessible to my colleagues and decision-makers. 

### Diagnostics and product assurance

But imagine you are standing on stage presenting these results and you start recalling all the assumptions made that have accumulated over the course of this study. For instance, think about how important the assumption that the underlying distribution is Weibull was to the analysis. Our fitted estimates of the coefficients depend on it, the interpretable ratios are built upon the quantiles and hazard of the Weibull, and if we wanted to predict the time to death then our predictions using this model would depend on that assumption as well. We seem to be betting the quality of our product on something that we haven't really tested. Really, we should treat our models the same way we treat people who think they dress well, give them a third-party opinion. Notice that since we computed our estimates so far with the Weibull assumptions, then their qualities will naturally look as if our data was actually Weibull, so they're not useful in discerning whether our model is a good fit. We need to have a quantity that we can estimate without the assumption and some idea of how the quantity would behave if the data were actually Weibull. Let $h(t)$ be the hazard function of the data when we write

$$
\log \int_{0}^th(t)dt = \log\int_0^t \frac{f(t)}{S(t)}dt = \log \int_0^t \frac{-d\log S(t)}{dt}dt = C_1 \log(t) + C_2,
$$
which is a true statement if the data is Weibull. The clever part is this, we can estimate the log cumulative hazard (method not shown here) on the left side without making assumptions about the distribution, and the last equality only holds if the distribution is Weibull. Now we know that if distributional assumption is correct, our estimates of the log cumulative hazard should look roughly linear when plotted against the log time. We do exactly this with our data and plot it against time on the log scale:

```{r}
m <- survfit(Surv(time, status)~sex, data = lung)

diagnosticsData <- WeibullDiag(Surv(time, status)~sex, data = lung, labels = names(m$strata))

data.frame(days = diagnosticsData$x,
           logHazard = diagnosticsData$y,
           sex = gsub("sex=", "", diagnosticsData$strata)) %>%
  ggplot() +
  geom_line(aes(x = days, y = logHazard, group = sex, color = sex)) +
  xlab("Days (log scale)") +
  ylab("Log Cumulative Hazard") +
  scale_color_discrete(name = "Sex") +
  theme_bw()
```

and we notice that there are spans of time where our model appears to be a good fit and also some early periods where the Weibull assumption may be questionable. These considerations here might never make it to a presentation slide, but they are important because they decide how much confidence we have in our results. My colleagues trust that I have vetted results as thoroughly as possible before a recommendation sees the light of day. In exchange for that trust, I provide assurance to them and myself by actively reading and even developing methods that might assure us of the quality of our decisions. And to be honest, it's a blast.
